{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aaf1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "from jax.random import gumbel\n",
    "import optax\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import jraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c08c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define the GNN part, which consists of featurizer, mp layers, and readout\n",
    "\n",
    "class GraphNetwork(hk.Module):\n",
    "    def __init__(self, *args, name=None, **kwargs):\n",
    "        super().__init__(name=name)\n",
    "        self.model = jraph.GraphNetwork(*args, **kwargs)\n",
    "    \n",
    "    def __call__(self, g: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "        return self.model(g)\n",
    "    \n",
    "class GraphEncoder(hk.Module):\n",
    "    \"\"\"\n",
    "    Encodes input Fine-Grained (FG) molecular graph and outputs a\n",
    "    continuous vector embedding of that graph deterministically.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers: int, \n",
    "                       edge_embedding_size: int,\n",
    "                       node_embedding_size: int,\n",
    "                       global_embedding_size: int, \n",
    "                       name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.n_layers = n_layers\n",
    "        edge_output_sizes = []\n",
    "        node_output_sizes = []\n",
    "        global_output_sizes = [, 2+out_embedding_size]\n",
    "        def make_embed_edge_fn(activation=jax.nn.relu):\n",
    "            def f(edge_feats): # single layer for simplicity\n",
    "                return hk.nets.MLP([edge_embedding_size], activation=activation)(edge_feats)\n",
    "            return f\n",
    "        \n",
    "        def make_embed_node_fn(activation=jax.nn.relu):\n",
    "            def f(node_feats):\n",
    "                return hk.nets.MLP([node_embedding_size], activation=activation)(node_feats)\n",
    "            return f\n",
    "        \n",
    "        def make_update_edge_fn(activation=jax.nn.relu):\n",
    "            @jraph.concatenated_args\n",
    "            def f(feats):\n",
    "                return hk.nets.MLP(edge_output_sizes, activation=activation)(feats)\n",
    "            return f\n",
    "        \n",
    "        def make_update_node_fn(activation=jax.nn.relu):\n",
    "            def f(node_feats, sender_feats, receiver_feats, global_feats):\n",
    "                return hk.nets.MLP(node_output_sizes, activation=activation)(\n",
    "                    jnp.concatenate([node_feats, receiver_feats], axis=1) # only aggr over msgs from incoming edges\n",
    "                )\n",
    "            return f\n",
    "        \n",
    "        def make_update_global_fn(activation=jax.nn.relu):\n",
    "            @jraph.concatenated_args\n",
    "            def f(feats):\n",
    "                return hk.nets.MLP(global_output_sizes, activation=activation)(feats)\n",
    "            return f\n",
    "        \n",
    "        self.featurizer = jraph.GraphMapFeatures(embed_edge_fn=make_embed_edge_fn(),\n",
    "                                                 embed_node_fn=make_embed_node_fn(), \n",
    "                                                 embed_global_fn=None)\n",
    "        self.mp_layers = [GraphNetwork(update_edge_fn=make_update_edge_fn(), \n",
    "                                       update_node_fn=make_update_node_fn(), \n",
    "                                       update_global_fn=None) for _ in range(n_layers)]\n",
    "        self.readout = GraphNetwork(update_edge_fn=make_update_edge_fn(), \n",
    "                                    update_node_fn=make_update_node_fn(), \n",
    "                                    update_global_fn=make_update_global_fn)\n",
    "        \n",
    "    def __call__(self, g: jraph.GraphsTuple):\n",
    "        g = self.featurizer(g)\n",
    "        for layer in self.mp_layers:\n",
    "            g = layer(g)\n",
    "        g = self.readout(g)\n",
    "        return g.globals # extract graph level latent feature\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbea3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_node_features(g: jraph.GraphsTuple, new_nodes) -> jraph.GraphsTuple:\n",
    "    nodes, edges, receivers, senders, globals_, n_node, n_edge = g\n",
    "    n_node = jnp.array([len(nodes)])\n",
    "    return jraph.GraphsTuple(new_nodes, edges, receivers, senders, globals_, n_node, n_edge)\n",
    "\n",
    "\n",
    "class GraphNVPLayer(hk.Module):\n",
    "    def __init__(self, dim, mask_dim, hidden_dim = 16, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.dim = dim\n",
    "        self.mask_dim = mask_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        edge_output_sizes = [hidden_dim, hidden_dim]\n",
    "        node_output_sizes_trans = [hidden_dim, hidden_dim, 1]\n",
    "        node_output_sizes_scale = [hidden_dim, hidden_dim, dim]\n",
    "        def make_mlp_edge_update(activation):\n",
    "            @jraph.concatenated_args\n",
    "            def f(feats):\n",
    "                return hk.nets.MLP(edge_output_sizes, activation=activation)(feats)\n",
    "            return f\n",
    "        def make_mlp_node_update(activation, node_output_sizes):\n",
    "            def f(node_feats, sender_feats, receiver_feats, global_feats):\n",
    "                return hk.nets.MLP(node_output_sizes, activation=activation)(\n",
    "                    jnp.concatenate([node_feats, receiver_feats], axis=1) # only aggr over msgs from incoming edges\n",
    "                )\n",
    "            return f\n",
    "        self.mp_trans = GraphNetwork(update_edge_fn=make_mlp_edge_update(jax.nn.relu), \n",
    "                                     update_node_fn=make_mlp_node_update(jax.nn.relu, \n",
    "                                                                         node_output_sizes_trans), \n",
    "                                     update_global_fn=None)\n",
    "        self.mp_scale = GraphNetwork(update_edge_fn=make_mlp_edge_update(jax.nn.relu), \n",
    "                                     update_node_fn=make_mlp_node_update(jax.nn.tanh,\n",
    "                                                                         node_output_sizes_scale), \n",
    "                                     update_global_fn=None)\n",
    "    def mask_graph(self, g):\n",
    "        nodes = g.nodes\n",
    "        mask = jnp.ones_like(nodes)\n",
    "        mask[:, self.mask_dim] = 0\n",
    "        g_masked = replace_node_features(g, nodes * mask)\n",
    "        return g_masked, mask\n",
    "    \n",
    "    def forward(self, g: jraph.GraphsTuple) -> Tuple[jraph.GraphsTuple, jnp.ndarray]:\n",
    "        g_masked, mask = self.mask_graph(g)\n",
    "        scale, trans = self.mp_scale(g_masked).nodes, self.mp_trans(g_masked).nodes\n",
    "        new_nodes = nodes * jnp.exp(scale * mask) + (trans * mask)\n",
    "        logdetJ = jnp.sum(scale * mask)\n",
    "        g_new = replace_node_features(g, new_nodes)\n",
    "        return g_new, logdetJ\n",
    "        \n",
    "    def reverse(self, g: jraph.GraphsTuple) -> Tuple[jraph.GraphsTuple, jnp.ndarray]:\n",
    "        g_masked, mask = self.mask_graph(g)\n",
    "        scale, trans = self.mp_scale(g_masked).nodes, self.mp_trans(g_masked).nodes\n",
    "        new_nodes = (nodes - (trans * mask)) / jnp.exp(scale * mask)\n",
    "        logdetJ = -jnp.sum(scale * mask)\n",
    "        g_new = replace_node_features(g, new_nodes)\n",
    "        return g_new, logdetJ\n",
    "    \n",
    "class GraphNVPBlock(hk.Module):\n",
    "    def __init__(self, dim, hidden_dim = 16, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.dim = dim\n",
    "        self.layers = [GraphNVPLayer(dim, mask_dim, hidden_dim) for mask_dim in range(dim)]\n",
    "        \n",
    "    def forward(self, g: jraph.GraphsTuple) -> Tuple[jraph.GraphsTuple, jnp.ndarray]:\n",
    "        ldj_sum = 0\n",
    "        for layer in self.layers:\n",
    "            g, ldj = layer.forward(g)\n",
    "        return g, ldj_sum\n",
    "        \n",
    "    def reverse(self, g: jraph.GraphsTuple) -> Tuple[jraph.GraphsTuple, jnp.ndarray]:\n",
    "        ldj_sum = 0\n",
    "        for layer in self.layers[::-1]:\n",
    "            g, ldj = layer.reverse(g)\n",
    "        return g, ldj_sum\n",
    "    \n",
    "class GraphNVP(hk.Module):\n",
    "    # The potential advantage of GraphNVP over GRevNet is that\n",
    "    # 1. This handles edge feature updates but the latter couldn't\n",
    "    # 2. The latter requires breaking node features into two halves which makes\n",
    "    # application to 3D coordinate as node features difficult. GraphNVP\n",
    "    # can iterate and update over each dimension using the rest features \n",
    "    # (see paper for more details) \n",
    "    def __init__(self, n_layers, dim, hidden_dim=16, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.layers = [GRevLayer(dim, hidden_dim) for _ in range(n_layers)]\n",
    "    \n",
    "    # these should be same as before, just copied\n",
    "    def forward(self, g: jraph.GraphsTuple) -> Tuple[jraph.GraphsTuple, jnp.ndarray]:\n",
    "        ldj_sum = 0\n",
    "        for layer in self.layers:\n",
    "            g, ldj = layer.forward(g)\n",
    "            ldj_sum += ldj\n",
    "        return g, ldj_sum\n",
    "        \n",
    "    def reverse(self, g: jraph.GraphsTuple) -> Tuple[jraph.GraphsTuple, jnp.ndarray]:\n",
    "        ldj_sum = 0\n",
    "        for layer in self.layers[::-1]:\n",
    "            g, ldj = layer.reverse(g)\n",
    "            ldj_sum += ldj\n",
    "        return g, ldj_sum\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4dff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoarseGrainingDecoder(hk.Module):\n",
    "    \"\"\"\n",
    "    Probabilistically decode the embedding from the previous encoder into\n",
    "    a Coarse-Grained (CG) molecular graph. Returns log proba as well as the\n",
    "    graph that we can directly evaluate energy on.\n",
    "    \"\"\"\n",
    "    def __init__(self, flow_dim=2, max_nodes=100, n_hidden=16, n_edge_feats=8, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.max_nodes = max_nodes\n",
    "        self.max_edges = (max_nodes)*(max_nodes-1)//2\n",
    "        self.flow_dim = flow_dim\n",
    "        self.node_feat_shape = (max_nodes, flow_dim)\n",
    "        s, r = list(zip(*list(itertools.product(range(max_nodes), range(max_nodes))))) # transpose tupls\n",
    "        self.senders = list(s)\n",
    "        self.receivers = list(r)\n",
    "        self.mu_decoder = hk.nets.MLP([n_hidden, max_nodes*flow_dim], activation=jax.nn.relu)\n",
    "        self.sig_decoder = hk.nets.MLP([n_hidden, max_nodes*flow_dim], activation=jax.nn.relu) #?\n",
    "        self.edge_decoder = hk.nets.MLP([n_hidden, n_edge_feats], activation=jax.nn.relu)\n",
    "        \n",
    "    \n",
    "    def __call__(self, h):\n",
    "        # first and second position of h is mean and std embeddings\n",
    "        h_mu, h_sig = h\n",
    "        V_mu, V_sig = self.mu_decoder(h_mu), self.sig_decoder(h_sig)\n",
    "        V_mu, V_sig = jax.reshape(V_mu, shape=self.node_feat_shape), jax.reshape(V_sig, shape=self.node_feat_shape)\n",
    "        eps = jax.random.normal(hk.next_rng_key(), shape=self.node_feat_shape)\n",
    "        V = eps * jnp.exp(V_sig) + V_mu # v_sig is actually log(sig_z)\n",
    "        ll = -(jnp.sum(V_sig) + 0.5*jnp.sum(eps))# log likelihood, discard 1/2 log(2pi) term\n",
    "        eps2 = jax.random.normal(hk.next_rng_key(), )\n",
    "        E_ = jnp.array([jnp.concatenate((ri, rj)) for ri, rj in itertools.product(V, V)]) # |V|**2 * flow_dim*2 \n",
    "        E = self.edge_decoder(E) # |V|**2 * n_edge_feats\n",
    "        \n",
    "        # build graph and pass to flow model\n",
    "        G = jraph.GraphsTuple(n_node=self.max_nodes, n_edge=self.max_edges, nodes=V, edges=E,\n",
    "                              globals=None, senders=self.senders, receivers=self.receivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c0dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd33e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "N = 100\n",
    "a, b = list(zip(*list(itertools.product(range(N), range(N)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95a9780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_():\n",
    "    mlp = hk.nets.MLP([8, 16, 8])\n",
    "    mlp_in = jnp.ones([1, 2])\n",
    "    y = mlp(mlp_in)\n",
    "    return y\n",
    "\n",
    "f = hk.without_apply_rng(hk.transform(f))\n",
    "params = f.init(rng=jax.random.PRNGKey(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3d0a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.apply(params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de00bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.repeat(np.arange(0, 5), 2).reshape((5, 2))\n",
    "b = np.repeat(np.arange(5, 10), 2).reshape((5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8347f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = np.array([np.concatenate((ri, rj)) for ri, rj in itertools.product(a, b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba1867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 5, 5],\n",
       "       [0, 0, 6, 6],\n",
       "       [0, 0, 7, 7],\n",
       "       [0, 0, 8, 8],\n",
       "       [0, 0, 9, 9],\n",
       "       [1, 1, 5, 5],\n",
       "       [1, 1, 6, 6],\n",
       "       [1, 1, 7, 7],\n",
       "       [1, 1, 8, 8],\n",
       "       [1, 1, 9, 9],\n",
       "       [2, 2, 5, 5],\n",
       "       [2, 2, 6, 6],\n",
       "       [2, 2, 7, 7],\n",
       "       [2, 2, 8, 8],\n",
       "       [2, 2, 9, 9],\n",
       "       [3, 3, 5, 5],\n",
       "       [3, 3, 6, 6],\n",
       "       [3, 3, 7, 7],\n",
       "       [3, 3, 8, 8],\n",
       "       [3, 3, 9, 9],\n",
       "       [4, 4, 5, 5],\n",
       "       [4, 4, 6, 6],\n",
       "       [4, 4, 7, 7],\n",
       "       [4, 4, 8, 8],\n",
       "       [4, 4, 9, 9]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7879842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=jnp.ones((5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52011746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0., 1.],\n",
       "             [0., 1.],\n",
       "             [0., 1.],\n",
       "             [0., 1.],\n",
       "             [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.at[:, 0].set(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fed86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jax]",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
